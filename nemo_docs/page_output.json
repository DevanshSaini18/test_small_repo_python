[
  {
    "text": "Architecture Overview\n\nThis document summarizes the Enterprise Todo Platform architecture, its core components, and how they interact to deliver a multi-tenant, production-ready SaaS API.\n\nCore components\n\n- API application: FastAPI app defined in main.py. Exposes REST surface under /api/v1 via a centralized APIRouter (app/routes.py). Includes middleware for CORS, request timing (X-Process-Time header) and a global exception handler.\n\n- Routing & domain layer: app/routes.py implements the HTTP endpoints (auth, organizations, teams, items, comments, tags, api-keys, webhooks, analytics, activity). Routes rely on dependency injection (DB sessions, auth, RBAC) and delegate business logic to service functions.\n\n- Data layer: SQLAlchemy declarative Base and engine live in app/database.py. get_db() yields request-scoped Session objects used across routes and services. In development the project defaults to SQLite; production configuration uses DATABASE_URL (Postgres) as defined in docker-compose.yml and docs.\n\n- Authentication & Authorization: JWT-based user auth (login/register) plus API keys and RBAC enforced at route-dependency level (see routes and dependencies). Tokens are created and verified in the auth layer and consumed by route dependencies.\n\n- Services & models (domain logic): Routes call into service layer functions (services.py) which operate over SQLAlchemy ORM models (models.py) to implement creation, queries, updates and analytics. Activity logs, usage logs, webhooks and API key entities provide multi-tenant observability and integration hooks.\n\nInfrastructure & deployment\n\n- Containerization: Dockerfile builds a Python 3.11 image, installs dependencies and exposes port 8000; includes a healthcheck that queries /health. docker-compose.yml orchestrates three services: db (Postgres container with persistent volume), app (built from Dockerfile), and nginx (reverse proxy). Environment variables configure DATABASE_URL, SECRET_KEY, CORS_ORIGINS, etc.\n\n- Reverse proxy & TLS: nginx service (configured through mounted nginx.conf and ssl volumes in docker-compose) serves TLS termination and forwards to the app container.\n\nOperational & observability primitives\n\n- Health endpoint: GET /health provides liveness info used by container healthchecks.\n- Request logging: main.py logs method, path, response status and timing; the framework also exposes OpenAPI docs (/docs, /redoc).\n- DB migrations: schema creation is triggered via Base.metadata.create_all(bind=engine) in main.py; docs recommend Alembic for production migrations.\n\nScalability patterns\n\n- Stateless app instances sit behind nginx/load balancer; any stateful data (DB, uploads) persisted in external services (Postgres, host volume). Docker Compose and cloud deployment guides in docs/deployment.md show options for horizontal scaling, external RDS, and ALB/ingress setups.\n\nFiles referenced:\n",
    "source_files": [
      "main.py",
      "app/routes.py",
      "app/database.py",
      "Dockerfile",
      "docker-compose.yml",
      "docs/index.md",
      "docs/deployment.md",
      "app/__init__.py"
    ]
  },
  {
    "text": "# Getting Started\n\nThis guide walks through running the Enterprise Todo Platform locally, authenticating and making your first API request.\n\n## Prerequisites\n- Python 3.11+ (pyproject and .python-version)\n- Poetry (recommended) or pip\n- Docker (optional, for Postgres)\n- Git\n\n## Clone\n```bash\ngit clone https://github.com/your-org/fastapi-todo-saas.git\ncd fastapi-todo-saas\n```\n\n## Install dependencies\nUsing Poetry:\n```bash\npoetry install\npoetry shell\n```\nOr pip:\n```bash\npip install -r requirements.txt\n```\n(See pyproject.toml / requirements.txt)\n\n## Configure environment\nCopy `.env.example` to `.env` and update values (DATABASE_URL, SECRET_KEY, CORS_ORIGINS, etc.). The app reads common settings from environment variables defined in .env.example.\n\n## Database\n- Development default: SQLite (app/database.py uses sqlite:///./test.db).\n- Production / Docker: PostgreSQL. Start via docker-compose (docker-compose.yml):\n```bash\ndocker compose up -d db\n```\nCreate schema using migrations (Alembic):\n```bash\nalembic upgrade head\n```\nNote: the app also calls Base.metadata.create_all(bind=engine) on startup (main.py) to create tables when using the bundled SQLite dev DB.\n\n## Run the app\n```bash\nuvicorn main:app --reload\n```\nThe API is available at http://localhost:8000 and docs at /docs. main.py sets CORS, request timing header X-Process-Time and a global exception handler.\n\n## Authentication flow\n- Register: POST /api/v1/auth/register (see app/routes.py)\n- Login: POST /api/v1/auth/login returns JWT (app/auth.py handles token creation)\n- Use token in requests: Authorization: Bearer <token>\n- API Keys: Admins can create API keys and use X-API-Key header\n\n## First API call \u2014 create an item\nExample request (replace <token>):\n```bash\ncurl -X POST http://localhost:8000/api/v1/items \\\n  -H \"Authorization: Bearer <token>\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"title\":\"Implement feature X\",\"description\":\"Details\",\"status\":\"todo\",\"priority\":\"high\",\"due_date\":\"2025-12-31T23:59:59\",\"team_id\":1,\"assignee_ids\":[2],\"tag_ids\":[1]}'\n```\nResponse: JSON representation of the created item (routes and schemas define payloads).\n\n## Next steps\n- Review full API surface in docs/api-reference.md\n- Generate API keys for service integrations\n- Inspect app/services.py and app/models.py for business and data models\n\nReferenced files: docs/getting-started.md, main.py, app/auth.py, app/routes.py, app/database.py, .env.example, docker-compose.yml, docs/api-reference.md\n",
    "source_files": [
      "docs/getting-started.md",
      "main.py",
      "app/auth.py",
      "app/routes.py",
      "app/database.py",
      ".env.example",
      "docker-compose.yml",
      "docs/api-reference.md"
    ]
  },
  {
    "text": "# API Reference\n\nThis API Reference summarizes the REST surface exposed by the Enterprise Todo Platform backend (see app/routes.py and docs/api-reference.md). It maps routes to request/response shapes (app/schemas.py), auth and access control (app/auth.py, app/dependencies.py, app/models.py), and service behavior (app/services.py). Interactive OpenAPI docs are served at /docs (main.py).\n\n## Authentication\n\nSupported methods (enforced in dependencies):\n- JWT Bearer: Authorization: Bearer <token> \u2014 tokens created/verified via app/auth.py (create_access_token, decode_access_token).\n- API Key: X-API-Key: <key> \u2014 validated by verify_api_key in app/dependencies.py and represented by APIKey model in app/models.py.\n\nUser roles (app/models.py) drive RBAC: owner, admin, member, viewer. Dependency require_role(...) enforces role hierarchy.\n\n## Primary resource groups (routes implementation: app/routes.py)\n\n- Authentication\n  - POST /auth/register -> UserCreate -> UserRead\n  - POST /auth/login -> Token\n  - GET /auth/me -> current UserRead\n\n- Organizations\n  - POST /organizations -> OrganizationCreate -> OrganizationRead\n  - GET /organizations/current -> OrganizationRead\n  - GET /organizations/{org_id}/users -> List[UserRead]\n\n- Teams\n  - POST /teams (admin) -> TeamCreate -> TeamRead\n  - POST /teams/{team_id}/members/{user_id} (admin)\n\n- Items\n  - POST /items -> ItemCreate -> ItemRead\n  - GET /items/{item_id} -> ItemRead\n  - GET /items -> List[ItemRead] (filters: team_id, status, priority, assigned_to, skip, limit)\n  - PUT /items/{item_id} -> ItemUpdate -> ItemRead\n  - DELETE /items/{item_id}\n\n- Comments\n  - POST /comments -> CommentCreate -> CommentRead\n  - GET /items/{item_id}/comments -> List[CommentRead]\n\n- Tags\n  - POST /tags -> TagCreate -> TagRead\n  - GET /tags -> List[TagRead]\n\n- API Keys (admin)\n  - POST /api-keys -> APIKeyCreate -> APIKeyRead\n  - GET /api-keys -> List[APIKeyRead]\n\n- Webhooks (admin)\n  - POST /webhooks -> WebhookCreate -> WebhookRead\n  - GET /webhooks -> List[WebhookRead]\n\n- Activity\n  - GET /activity -> List[ActivityLogRead] (optional item_id, limit)\n\n- Analytics\n  - GET /analytics/items -> ItemAnalytics (aggregates via app/services.py)\n  - GET /analytics/usage?days=N (admin) -> UsageAnalytics\n\n## Schemas and models\n\nRequest and response shapes are defined in app/schemas.py (Organization*, User*, Team*, Item*, Comment*, Tag*, APIKey*, Webhook*, ActivityLog*, analytics shapes). DB models live in app/models.py and include enums used by schemas: ItemStatus, PriorityLevel, UserRole, SubscriptionTier.\n\n## Behavior notes (service layer)\n\nBusiness logic, data validation and side-effects (activity logging, API key generation, analytics aggregation) are implemented in app/services.py. Examples: create_item adds assignees/tags and logs activity; get_item_analytics computes counts by status/priority and averages.\n\n## Errors, rate limits, and webhooks\n\nStandardized error responses (400/401/403/404/500) are documented in docs/api-reference.md. Rate limits are tiered by subscription tier (docs). Webhooks emit JSON events and include HMAC-SHA256 signature verification (X-Signature) using webhook secret (Webhook model).\n\nRelevant files: app/routes.py, app/schemas.py, app/dependencies.py, app/services.py, app/auth.py, app/models.py, docs/api-reference.md, main.py\n",
    "source_files": [
      "app/routes.py",
      "app/schemas.py",
      "app/dependencies.py",
      "app/services.py",
      "app/auth.py",
      "app/models.py",
      "docs/api-reference.md",
      "main.py"
    ]
  },
  {
    "text": "## Authentication & Authorization\n\nThis codebase implements combined JWT-based user authentication, API key access for machine clients, and role-based authorization enforced via FastAPI dependencies.\n\nKey components\n\n- app/auth.py\n  - Password hashing: get_password_hash() and verify_password() using passlib CryptContext (bcrypt).\n  - JWT tokens: create_access_token(data, expires_delta) encodes payload (adds exp) with SECRET_KEY and HS256; decode_access_token(token) verifies and returns the payload.\n  - API key generation: generate_api_key() returns a secure key prefixed with \"sk_\".\n  - Constants: SECRET_KEY, ALGORITHM, ACCESS_TOKEN_EXPIRE_MINUTES control token behavior.\n\n- app/models.py\n  - User model: fields include id, email, username, hashed_password, role (UserRole enum), is_active, organization_id, last_login.\n  - UserRole enum: OWNER, ADMIN, MEMBER, VIEWER used for RBAC checks.\n  - APIKey model: key, name, organization_id, is_active, last_used_at, expires_at; Organization model links users and API keys.\n\n- app/dependencies.py\n  - HTTPBearer security is used to extract Authorization bearer tokens.\n  - get_current_user: decodes JWT (decode_access_token), expects payload[\"sub\"] = user.id, loads user from DB, ensures is_active, updates last_login and commits.\n  - get_current_active_user: simple wrapper enforcing user.is_active.\n  - get_current_organization: resolves organization for current_user and ensures org is active.\n  - require_role(required_role): dependency factory implementing a role hierarchy mapping (VIEWER < MEMBER < ADMIN < OWNER); raises 403 if current_user.role is insufficient.\n  - verify_api_key: reads X-API-KEY header, looks up APIKey row, ensures is_active and not expired, updates last_used_at, returns associated Organization.\n\n- app/routes.py\n  - Authentication endpoints: POST /auth/register (UserCreate -> create_user), POST /auth/login (UserLogin -> verifies password -> returns Token with access_token created via create_access_token), GET /auth/me (returns current user via get_current_active_user).\n  - Authorization usage: routes use Dependencies to restrict actions (e.g., require_role(UserRole.ADMIN) for team creation, API key management, webhook management, and admin analytics endpoints). Several resource routes also depend on get_current_organization to enforce tenancy.\n\n- app/services.py\n  - create_user hashes passwords (get_password_hash) and persists User rows; create_api_key uses generate_api_key and persists APIKey rows; log_activity records actions for auditing.\n\nAuthentication flow summary\n\n1. User registers via /auth/register -> create_user hashes password and creates User.\n2. User logs in via /auth/login -> verify_password; on success create_access_token(data={\"sub\": user.id}) returns JWT bearer token.\n3. Protected endpoints require Authorization: Bearer <token> (resolved via HTTPBearer -> get_current_user -> get_current_organization); role checks enforce RBAC via require_role.\n4. Machine clients may use X-API-KEY header validated by verify_api_key, which returns the Organization context.\n\nSource files\n",
    "source_files": [
      "app/auth.py",
      "app/dependencies.py",
      "app/models.py",
      "app/routes.py",
      "app/services.py",
      "app/schemas.py"
    ]
  },
  {
    "text": "## Data Model & Schemas\n\nThis project uses SQLAlchemy ORM for the canonical relational data model and Pydantic for request/response schemas. The database bootstrap provides a declarative Base and a per-request session dependency for FastAPI.\n\nKey components (app/models.py)\n- Association tables: user_teams, item_tags, item_assignees implement many-to-many relations between users-teams, items-tags, and items-assignees.\n- Enums: PriorityLevel (low, medium, high, urgent), ItemStatus (todo, in_progress, in_review, done, archived), UserRole (owner, admin, member, viewer), SubscriptionTier (free, starter, professional, enterprise).\n- Organization: core tenant entity with subscription_tier, quotas (max_users, max_items), is_active, timestamps. Relationships to users, teams, items, api_keys, webhooks, usage_logs. Cascades configured to delete-orphan for owned children.\n- User: stores email/username/hashed_password, role, organization_id and relationships to teams (many-to-many), created_items, assigned_items (many-to-many), comments, activity_logs.\n- Team: belongs to an Organization; members via user_teams; holds items.\n- Tag: simple tag entity with name and color; many-to-many to Item via item_tags.\n- Item: central work unit with title, description, status, priority, due_date, estimated/actual hours, relational fields (organization_id, team_id, created_by_id, parent_item_id), timestamps (created_at, updated_at, completed_at). Relationships: creator, assignees, tags, comments, attachments, activity_logs. Self-referential parent/ subtasks via parent_item and backref subtasks.\n- Comment: content, item_id, author_id, timestamps; back-populates item and author.\n- Attachment: filename, file_path, file_size, mime_type, item and uploaded_by relations.\n- ActivityLog: generic audit entries (action, entity_type, entity_id, details JSON string), linked to user and optionally item.\n- APIKey: org-scoped secrets with key, name, is_active, last_used_at, expires_at.\n- Webhook: url, events (comma-separated), secret for verification, is_active.\n- UsageLog: per-organization request telemetry (endpoint, method, status_code, response_time_ms, timestamp).\n\nPydantic schemas (app/schemas.py)\n- Mirror the models with Base / Create / Update / Read variants for major entities: Organization, User, Team, Tag, Item, Comment, Attachment, ActivityLog, APIKey, Webhook.\n- Read schemas enable orm_mode to serialize SQLAlchemy objects. Nested relationships are represented (e.g., ItemRead includes assignees: List[UserRead], tags: List[TagRead]).\n- ItemCreate supports team_id, parent_item_id, assignee_ids, tag_ids. ItemUpdate exposes partial updates including status, priority, assignee_ids, tag_ids.\n- Auth/session schemas include Token and UserLogin types.\n- Analytics schemas: ItemAnalytics and UsageAnalytics summarize computed metrics for dashboards.\n\nDatabase bootstrap (app/database.py)\n- SQLAlchemy engine and SessionLocal configured (default SQLALCHEMY_DATABASE_URL = sqlite:///./test.db). Declarative Base exported as Base. get_db() yields a request-scoped SessionLocal for dependency injection in FastAPI routes/services.",
    "source_files": [
      "app/models.py",
      "app/schemas.py",
      "app/database.py"
    ]
  },
  {
    "text": "## Services Layer (Business Logic)\n\nThe services layer (app/services.py) centralizes domain logic and DB interactions for organizations, users, teams, items, comments, tags, API keys, webhooks, activity logs, usage logging and analytics. All service functions accept an SQLAlchemy Session and operate on ORM models (app/models.py) with Pydantic request/response shapes defined in app/schemas.py.\n\nKey responsibilities and patterns\n\n- Transactional writes: create/update/delete operations use db.add/db.commit/db.refresh and occasionally db.flush to ensure relations (e.g., many-to-many assignees/tags) are persisted and IDs available.\n\n- Schema-driven inputs: service creators and updaters accept Pydantic schema objects (e.g., OrganizationCreate, UserCreate, ItemCreate, ItemUpdate) and map fields to ORM models.\n\n- Authentication helpers: password hashing and API key generation are delegated to auth utilities (app/auth.py) \u2014 create_user hashes passwords; create_api_key calls generate_api_key().\n\n- Activity logging: log_activity(...) creates ActivityLog records for major domain events (create/update/delete/comment). Most mutating services call log_activity to persist audit entries.\n\n- Relationship management: create_item and update_item explicitly manage many-to-many relations (assignees, tags) by querying the User/Tag models and assigning lists to db_item.assignees / db_item.tags. Team membership is handled similarly in add_user_to_team.\n\n- Partial updates and change tracking: update_item uses ItemUpdate.dict(exclude_unset=True) to apply only changed fields, records old\u2192new diffs in a changes dict, serializes changes to JSON and logs them via ActivityLog. It also sets completed_at when status becomes DONE.\n\n- Query & filter patterns: read services use SQLAlchemy queries with optional filters (team_id, status, priority, assigned_to) and joins for assignee-based filtering. Pagination is supported via offset/limit.\n\n- Aggregations & analytics: get_item_analytics and get_usage_analytics use SQLAlchemy func (count, avg) and in-memory aggregation to produce metrics such as by-status/by-priority counts, overdue counts, average completion time, request volumes, avg response time and error rate.\n\n- Lightweight validators: read functions return Optional[T] or empty lists for missing/unauthorized resources (e.g., get_item returns None when not found; create_comment verifies item belongs to org).\n\nPrimary entry points (examples)\n\n- Organization: create_organization, get_organization\n- Users: create_user, get_user_by_email, get_users_by_organization\n- Teams: create_team, add_user_to_team\n- Items: create_item, get_item, get_items, update_item, delete_item\n- Comments: create_comment, get_comments_by_item\n- Tags: create_tag, get_tags\n- API Keys / Webhooks: create_api_key, get_api_keys, create_webhook, get_webhooks\n- Activity & Usage: log_activity, get_activity_logs, log_usage, get_usage_analytics\n\nSource files\n",
    "source_files": [
      "app/services.py",
      "app/models.py",
      "app/schemas.py",
      "app/auth.py"
    ]
  },
  {
    "text": "## Routes & Endpoints\n\nThis module (app/routes.py) defines the FastAPI HTTP surface for the Enterprise Todo Platform. Routes are organized by feature area and delegate business logic to the service layer (app/services.py). Request/response validation and shapes are expressed with Pydantic schemas (app/schemas.py). Security and multi-tenant access control rely on dependencies in app/dependencies.py and authentication helpers in app/auth.py.\n\nKey characteristics\n- Grouped by responsibility: Authentication, Organizations, Teams, Items, Comments, Tags, API Keys, Webhooks, Activity, Analytics.\n- Dependency-based access control: get_current_active_user, get_current_organization, require_role(UserRole.ADMIN) are applied per-route to enforce authentication, organization scoping, and RBAC.\n- Consistent response models and status codes: decorator-level response_model and status_code annotations (e.g., 201 CREATED for creates, 204 NO_CONTENT for deletes).\n- Filtering, paging, and validation: List endpoints use Query parameters (e.g., /items supports team_id, status, priority, assigned_to, skip, limit). Analytics endpoints accept constrained query params (days between 1 and 90).\n- Error handling: Routes raise HTTPException with appropriate HTTP status codes when services indicate not-found, unauthorized or invalid states.\n\nRepresentative endpoints\n- Authentication\n  - POST /auth/register -> UserCreate -> UserRead (201)\n  - POST /auth/login -> UserLogin -> Token (JWT) on success\n  - GET /auth/me -> current user (requires bearer token)\n\n- Organization\n  - POST /organizations -> OrganizationCreate -> OrganizationRead (201)\n  - GET /organizations/current -> OrganizationRead (scoped to current user)\n  - GET /organizations/{org_id}/users -> List[UserRead] (ensures current user belongs to org)\n\n- Teams (Admin)\n  - POST /teams -> TeamCreate -> TeamRead (201)\n  - POST /teams/{team_id}/members/{user_id} -> add user to team\n\n- Items\n  - POST /items -> ItemCreate -> ItemRead (201)\n  - GET /items/{item_id} -> ItemRead\n  - GET /items -> List[ItemRead] (filters: team_id, status, priority, assigned_to; pagination via skip & limit)\n  - PUT /items/{item_id} -> ItemUpdate -> ItemRead\n  - DELETE /items/{item_id} -> 204 NO_CONTENT\n\n- Comments & Tags\n  - POST /comments -> CommentCreate -> CommentRead (201)\n  - GET /items/{item_id}/comments -> List[CommentRead]\n  - POST /tags -> TagCreate -> TagRead (201)\n  - GET /tags -> List[TagRead]\n\n- API Keys & Webhooks (Admin)\n  - POST /api-keys, GET /api-keys\n  - POST /webhooks, GET /webhooks\n\n- Activity & Analytics\n  - GET /activity -> List[ActivityLogRead] (optional item_id, limit)\n  - GET /analytics/items -> ItemAnalytics\n  - GET /analytics/usage -> UsageAnalytics (Admin, days query param)\n\nInteractions with other modules\n- app/services.py: performs DB operations and domain logic invoked by routes.\n- app/schemas.py: defines request/response Pydantic models used in route signatures.\n- app/dependencies.py & app/auth.py: implement authentication, JWT creation/validation, API key validation and RBAC.\n- app/models.py / app/database.py: underlying ORM models and DB session used by services invoked from routes.\n\nSource files\n",
    "source_files": [
      "app/routes.py",
      "app/services.py",
      "app/schemas.py",
      "app/dependencies.py",
      "app/auth.py",
      "app/models.py",
      "app/database.py"
    ]
  },
  {
    "text": "## Database Setup & Migrations\n\nOverview\n\nThis project uses SQLAlchemy core + ORM for its persistence layer. The database configuration, session factory, and declarative base are defined in app/database.py; all ORM models are declared in app/models.py and register themselves on the shared Base. At application startup main.py invokes SQLAlchemy's metadata.create_all to ensure schema objects exist.\n\nEngine and Connection URL\n\n- The engine is created in app/database.py via create_engine(SQLALCHEMY_DATABASE_URL).\n- The repository default URL is sqlite:///./test.db. For SQLite the engine is created with connect_args={\"check_same_thread\": False} to allow multi-threaded access from the ASGI server.\n\nSession management\n\n- A scoped session factory is provided as SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine).\n- A dependency generator get_db() yields a new SessionLocal instance per request and ensures db.close() in a finally block. This dependency is consumed by route/service functions via FastAPI's Depends.\n\nDeclarative Base & Models\n\n- Base = declarative_base() is the shared metadata registry used by all models in app/models.py (association tables, enums, and ORM classes like Organization, User, Item, Team, Tag, Comment, Attachment, APIKey, Webhook, UsageLog, ActivityLog, etc.).\n- Models import Base from app.database so their Table/Column definitions populate Base.metadata.\n\nSchema Creation at Startup\n\n- main.py calls Base.metadata.create_all(bind=engine) during application initialization, causing SQLAlchemy to create tables for all registered models against the configured engine at runtime.\n\nMigrations (current project state)\n\n- The codebase relies on SQLAlchemy's metadata.create_all for creating schema objects on startup (see main.py). There are no migration scripts or a migration tool (e.g., Alembic) present in the repository under the application sources.\n\nFiles\n\n- app/database.py \u2014 engine, SessionLocal, Base, get_db dependency.\n- app/models.py \u2014 ORM models and association tables that populate Base.metadata.\n- main.py \u2014 application bootstrap that invokes Base.metadata.create_all(bind=engine) at startup.\n\nThis setup centralizes the engine/session/base definitions and wires model metadata into application startup creation of schema objects via create_all.",
    "source_files": [
      "app/database.py",
      "app/models.py",
      "main.py"
    ]
  },
  {
    "text": "## Deployment & Infrastructure\n\nThis project is packaged for containerized deployments and includes curated guidance and artifacts for local, Docker Compose, and cloud-hosted deployments.\n\nKey components\n- Dockerfile: production image based on python:3.11-slim; installs system deps, application dependencies (Poetry/pip fallback), copies source, exposes port 8000, creates uploads directory and defines a HEALTHCHECK against /health.\n- docker-compose.yml: multi-service composition for local/dev stacks with PostgreSQL (postgres:15-alpine), app service (builds from Dockerfile), and an Nginx reverse proxy. Declares a postgres_data volume and mounts ./uploads into the app container.\n- .env.example: canonical environment variables (DATABASE_URL, SECRET_KEY, CORS_ORIGINS, DEBUG, rate limits, webhook/file settings, logging). Use these for runtime configuration.\n- docs/deployment.md: authoritative deployment instructions covering Docker Compose, AWS (Elastic Beanstalk, ECS/Fargate), DigitalOcean App Platform, SSL/TLS (Let's Encrypt + Certbot + Nginx config example), monitoring (Sentry snippet), Alembic migrations, health checks, scaling strategies, caching recommendations, backups, and maintenance checklist.\n- main.py: application entrypoint exposing /health and root endpoints, registering API router, creating DB schema via SQLAlchemy Base.metadata.create_all(bind=engine), and adding request-timing middleware. The /health endpoint is used by container health checks and orchestrators.\n\nDeployment options (summary)\n- Docker Compose (local/dev): docker-compose.yml orchestrates db, app, and nginx. Exposes ports 5432 (db) and 8000 (app) and mounts uploads and ssl/nginx config files.\n- Docker image: build with Dockerfile (docker build -t enterprise-todo:latest .). Image includes a HEALTHCHECK that calls the app /health endpoint.\n- Cloud platforms: docs include patterns for Elastic Beanstalk, ECS/Fargate (ECR, task definitions, ALB), and DigitalOcean App Platform (app.yaml example).\n\nOperational considerations documented\n- Environment variables: production secrets (SECRET_KEY, DATABASE_URL, CORS_ORIGINS, DEBUG) are surfaced in .env.example and referenced in compose/docs.\n- SSL/TLS: Nginx configuration for HTTP->HTTPS redirect and proxying to the app on port 8000; Let's Encrypt certbot commands are documented.\n- Health checks & monitoring: /health endpoint; Sentry integration snippet is provided in docs and recommended to be initialized in main.py.\n- Migrations & backups: Alembic migration workflow and PostgreSQL pg_dump examples for scheduled backups are included in docs/deployment.md.\n- Scaling & caching: horizontal scaling recommendations, use of load balancers, and Redis for caching are described.\n\nFiles\n- docker-compose.yml\n- Dockerfile\n- docs/deployment.md\n- .env.example\n- main.py\n- README.md",
    "source_files": [
      "docker-compose.yml",
      "Dockerfile",
      "docs/deployment.md",
      ".env.example",
      "main.py",
      "README.md"
    ]
  },
  {
    "text": "## Docker Compose & NGINX\n\nThis project uses Docker Compose to orchestrate a three-service stack: PostgreSQL (db), the FastAPI application (app), and an NGINX reverse proxy (nginx). The composition centralizes networking, persistent storage, and environment-driven configuration for local development and simple production deployments.\n\nKey components (see docker-compose.yml):\n\n- db (Postgres 15-alpine)\n  - Image: postgres:15-alpine\n  - Environment: POSTGRES_DB, POSTGRES_USER, POSTGRES_PASSWORD\n  - Persistent volume: postgres_data -> /var/lib/postgresql/data\n  - Exposes port 5432 and includes a healthcheck (pg_isready) used by depends_on to gate app startup.\n\n- app (FastAPI)\n  - Built from the repository Dockerfile (build: .)\n  - Exposes port 8000 to the host (8000:8000)\n  - Environment variables wired for DATABASE_URL, SECRET_KEY, CORS_ORIGINS, DEBUG\n  - Depends on db.service_healthy so the app waits for Postgres readiness\n  - Mounts ./uploads into /app/uploads for file persistence\n  - restart: unless-stopped policy\n\n- nginx (nginx:alpine)\n  - Acts as a fronting reverse proxy and TLS terminator\n  - Host ports: 80 and 443 published\n  - Mounts local nginx.conf into the container at /etc/nginx/nginx.conf (read-only) and an ./ssl directory into /etc/nginx/ssl for certificates\n  - Depends on app and restarts unless-stopped\n\nNGINX role and configuration (see docs/deployment.md and ./nginx.conf mapping in compose):\n\n- NGINX is configured to accept HTTP (port 80) and HTTPS (port 443) and proxy application traffic to the app backend (typically to http://localhost:8000 inside the nginx container). The deployment docs include a sample server block showing:\n  - HTTP -> HTTPS redirect\n  - SSL certificate and key paths (e.g., /etc/letsencrypt/live/.../fullchain.pem and privkey.pem)\n  - proxy_pass to the backend with typical proxy_set_header directives (Host, X-Real-IP, X-Forwarded-For, X-Forwarded-Proto)\n\nSSL + certificates\n- Certificates are expected under ./ssl and are mounted read-only into the nginx container. The docs reference Certbot for obtaining Let\u2019s Encrypt certificates and a sample TLS server configuration.\n\nOperational notes in compose\n- Service healthchecks and depends_on are used to order startup (db -> app -> nginx)\n- Volumes: postgres_data (named volume) for DB persistence and host bind for uploads and SSL/nginx configuration\n- Restart policy: services are configured to restart unless-stopped for resilience in simple deployments\n\nBringing the stack up\n- Build and run with: docker-compose up -d (docker-compose.yml and Dockerfile used to build the app image)\n- See docs/deployment.md for additional guidance on production TLS, load balancing, and cloud deployment patterns.\n\nRelevant files:\n- docker-compose.yml\n- Dockerfile\n- docs/deployment.md\n- nginx.conf (mount referenced by compose)\n",
    "source_files": [
      "docker-compose.yml",
      "Dockerfile",
      "docs/deployment.md",
      "nginx.conf"
    ]
  },
  {
    "text": "## Webhooks & API Keys\n\nThis section describes how API keys and webhooks are represented, created, authenticated, and consumed in the platform.\n\n### Data models\n- APIKey (app/models.py)\n  - Fields: id, key (unique string), name, organization_id, is_active (bool), last_used_at (datetime), created_at, expires_at\n  - Relationship: belongs to Organization\n- Webhook (app/models.py)\n  - Fields: id, url, events (comma-separated string of event types), is_active, secret (string for signature verification), organization_id, created_at\n  - Relationship: belongs to Organization\n\nSchemas (app/schemas.py)\n- APIKeyCreate: name, optional expires_at\n- APIKeyRead: id, key, name, is_active, created_at, expires_at, last_used_at\n- WebhookCreate: url, events, optional secret\n- WebhookRead / WebhookUpdate: id, url, events, is_active, organization_id, created_at\n\n### Creation and storage (services)\n- create_api_key(db, APIKeyCreate, org_id) (app/services.py)\n  - Uses auth.generate_api_key() to produce a secure key prefixed with \"sk_\" (app/auth.py)\n  - Persists APIKey record with expires_at and organization association\n- create_webhook(db, WebhookCreate, org_id) (app/services.py)\n  - Persists webhook url, events, secret and organization linkage\n\n### API surface (routes)\n- API Key endpoints (app/routes.py)\n  - POST /api-keys \u2014 create new API key (Admin only via require_role(UserRole.ADMIN))\n  - GET /api-keys \u2014 list API keys for organization (Admin only)\n- Webhook endpoints (app/routes.py)\n  - POST /webhooks \u2014 create webhook (Admin only)\n  - GET /webhooks \u2014 list webhooks (Admin only)\n\nRequest authentication: endpoints accept either JWT Bearer tokens (Authorization: Bearer <token>) or API keys (X-API-Key: <api_key>) as described in docs/api-reference.md and implemented in dependencies.py.\n\n### API key verification and lifecycle\n- verify_api_key dependency (app/dependencies.py)\n  - Reads X-API-Key header, looks up active APIKey\n  - Checks expires_at against current time; updates APIKey.last_used_at on success\n  - Resolves and returns associated Organization (and ensures org is active)\n- Keys are generated by generate_api_key() (app/auth.py) and stored as the full key (sk_...)\n- APIKey model tracks last_used_at to support auditing/rotation and expires_at for automatic invalidation\n\n### Webhook contract & signature verification\n- Event types (docs/api-reference.md): item.created, item.updated, item.deleted, comment.created, user.added\n- Payload format (docs/api-reference.md): JSON with keys event, timestamp, organization_id, data\n- Signature: requests sent to webhook endpoints include X-Signature header containing an HMAC-SHA256 signature computed with the webhook secret; docs/api-reference.md specifies HMAC-SHA256 verification using the stored secret\n\n### Integration notes\n- Creation/listing of keys and webhooks require admin role (routes + dependencies)\n- Webhooks store secret per organization for signature verification; platform records events (services.log_activity) that can be mapped to webhook dispatch (no dispatcher shown in code but contract defined in docs)\n\nSource files: app/models.py, app/schemas.py, app/services.py, app/routes.py, app/dependencies.py, app/auth.py, docs/api-reference.md, README.md\n",
    "source_files": [
      "app/models.py",
      "app/schemas.py",
      "app/services.py",
      "app/routes.py",
      "app/dependencies.py",
      "app/auth.py",
      "docs/api-reference.md",
      "README.md"
    ]
  },
  {
    "text": "## Analytics & Activity Logs\n\nOverview\n\nThe project captures operational and business-oriented telemetry via two primary subsystems: Activity Logs (domain-level events tied to users/items) and Usage Logs (API request-level metrics). These are persisted in the relational schema and exposed through service functions and REST endpoints for retrieval and basic aggregation.\n\nData model\n\n- ActivityLog (app/models.py)\n  - Fields: id, action (e.g. created, updated, deleted, commented), entity_type (item, comment, user, ...), entity_id, details (JSON string), user_id, item_id (nullable), created_at.\n  - Relationships: links to User and Item; organization association inferred through the user->organization relationship when querying.\n\n- UsageLog (app/models.py)\n  - Fields: id, organization_id, endpoint, method, status_code, response_time_ms, timestamp.\n  - Relationship: organization back-reference used for per-organization usage aggregation.\n\nActivity logging flow (services)\n\n- log_activity(db, action, entity_type, entity_id, user_id=None, item_id=None, details=None) (app/services.py)\n  - Creates and commits an ActivityLog row. Called from service operations (create_user, create_team, create_item, update_item, delete_item, create_comment, etc.) whenever an auditable change occurs.\n  - Details parameter is used to store change diffs (e.g. assignees or field changes) as a JSON string.\n\nRetrieval\n\n- get_activity_logs(db, org_id, item_id=None, limit=50) (app/services.py)\n  - Joins ActivityLog -> User and filters by User.organization_id to constrain results to an organization.\n  - Supports optional item_id filter and returns recent entries ordered by created_at desc (limit default 50).\n\n- Routes: GET /activity (app/routes.py)\n  - Query params: item_id (optional), limit (default 50, max 500)\n  - Authentication: any active user in organization (get_current_active_user). Response model: List[ActivityLogRead] (app/schemas.py).\n\nItem analytics (business metrics)\n\n- get_item_analytics(db, org_id) (app/services.py)\n  - Computes: total_items, counts broken down by Item.status (by_status) and PriorityLevel (by_priority), overdue_items (due_date < now and not DONE), completed_this_week (completed_at within last 7 days), avg_completion_time_hours (avg of actual_hours where present).\n  - Uses SQL aggregation (func.count, func.avg) and iterates enums for bucketed counts.\n\n- Route: GET /analytics/items (app/routes.py)\n  - Authentication: any active user in org. Response model: ItemAnalytics (app/schemas.py) with shape: total_items, by_status, by_priority, overdue_items, completed_this_week, avg_completion_time_hours.\n\nUsage analytics and logging\n\n- log_usage(db, org_id, endpoint, method, status_code, response_time_ms) (app/services.py)\n  - Persists a UsageLog row per API request (intended to be called by middleware or wrapped request handlers).\n\n- get_usage_analytics(db, org_id, days=7) (app/services.py)\n  - Aggregates UsageLog entries since (now - days) and returns: total_requests, requests_by_endpoint (counts per endpoint), avg_response_time_ms, error_rate (% of requests with status_code >= 400).\n\n- Route: GET /analytics/usage (app/routes.py)\n  - Query param: days (1..90, default 7)\n  - Authentication: Admin-only (require_role(UserRole.ADMIN)). Response model: UsageAnalytics (app/schemas.py).\n\nSchemas (app/schemas.py)\n\n- ActivityLogRead: id, action, entity_type, entity_id, details, user_id, created_at (ORM mode).\n- ItemAnalytics: total_items, by_status (dict), by_priority (dict), overdue_items, completed_this_week, avg_completion_time_hours.\n- UsageAnalytics: total_requests, requests_by_endpoint (dict), avg_response_time_ms, error_rate.\n\nAPI reference\n\n- docs/api-reference.md documents the endpoints: GET /activity, GET /analytics/items, GET /analytics/usage with example responses and notes about role restrictions (usage analytics requires admin).\n\nRelevant source files\n\n- app/models.py\n- app/services.py\n- app/schemas.py\n- app/routes.py\n- docs/api-reference.md\n",
    "source_files": [
      "app/models.py",
      "app/services.py",
      "app/schemas.py",
      "app/routes.py",
      "docs/api-reference.md"
    ]
  },
  {
    "text": "# File Uploads & Attachments\n\nThis document describes how file attachments are represented and configured in the codebase \u2014 the database model, the API schemas, and the environment settings that control upload storage and limits.\n\n## Data model (app/models.py)\n- Attachment table: attachments\n- Columns:\n  - id (int, PK)\n  - filename (string) \u2014 original filename\n  - file_path (string) \u2014 server-side path or storage key where the file is stored\n  - file_size (int) \u2014 bytes\n  - mime_type (string)\n  - item_id (FK -> items.id) \u2014 association to the Item the attachment belongs to\n  - uploaded_by_id (FK -> users.id) \u2014 user who uploaded the file\n  - created_at (datetime)\n- Relationships:\n  - item: relationship back_populates \"attachments\" on Item; Attachment.item points to the parent Item\n  - uploaded_by: relationship to User\n- Referential behavior:\n  - Attachment.item_id is defined with ondelete=\"CASCADE\" on the items FK, so attachments are deleted when their item is removed.\n  - Item model declares attachments = relationship(\"Attachment\", back_populates=\"item\", cascade=\"all, delete-orphan\")\n\n## API / Validation schema (app/schemas.py)\n- AttachmentRead Pydantic model (read-only representation):\n  - id, filename, file_size, mime_type, item_id, uploaded_by_id, created_at\n  - orm_mode = True\n- Note: ItemRead (the primary item response schema) in the current schemas does not include an attachments list field even though the Item model has an attachments relationship; AttachmentRead exists to represent attachment resources when returned by an endpoint or service.\n\n## Application-level usage (app/services.py, app/models.py)\n- The services module imports the Attachment model, indicating intended service-level handling, but there are no explicit create/download/delete attachment helper functions implemented in the service layer in the current code snapshot.\n- The Attachment model is integrated into the domain: Items have attachments and attachments are associated with Users (uploaded_by).\n\n## Configuration ( .env.example )\n- File upload configuration variables are provided in .env.example:\n  - MAX_UPLOAD_SIZE_MB=10 \u2014 maximum upload size (MB)\n  - UPLOAD_DIR=./uploads \u2014 default local filesystem upload directory\n- These variables reflect how uploads are expected to be constrained and where files should be stored by an upload implementation.\n\n## Project documentation references (README.md)\n- README lists \"File attachments (coming soon)\" under Collaboration, indicating attachment functionality is planned/partially modeled but not fully exposed via endpoints at present.\n\n## Summary of current state\n- Persistent model: Attachments are fully modeled in the database with fields to store metadata and storage pointers, and are linked to items and users with cascade delete behavior.\n- Validation/output: AttachmentRead exists to serialize attachment records.\n- Config: Upload size and directory are configurable via environment variables.\n- Service/API: The model and schema are present; explicit attachment CRUD endpoints and service helpers are not implemented in routes.py/services.py in the provided snapshot.\n\nRelevant files\n- app/models.py \u2014 Attachment model, Item relationship, cascade behavior\n- app/schemas.py \u2014 AttachmentRead schema\n- .env.example \u2014 MAX_UPLOAD_SIZE_MB and UPLOAD_DIR configuration variables\n- app/services.py \u2014 Attachment model imported (indicates service-level intent)\n- README.md \u2014 high-level note about file attachments (coming soon)\n",
    "source_files": [
      "app/models.py",
      "app/schemas.py",
      ".env.example",
      "app/services.py",
      "README.md"
    ]
  },
  {
    "text": "## Security & Rate Limiting\n\nThis section documents the platform's security primitives, authentication flows, RBAC enforcement, webhook signing, and rate limiting configuration.\n\n### Authentication\n- JWT-based user auth\n  - Tokens are issued and validated in app/auth.py (create_access_token, decode_access_token). Tokens include an exp claim; default expiry is 24 hours (ACCESS_TOKEN_EXPIRE_MINUTES). SECRET_KEY and ALGORITHM drive signing.\n  - Passwords are hashed/verified via passlib bcrypt (pwd_context) in app/auth.py (get_password_hash, verify_password).\n  - Token subject (`sub`) maps to User.id and is resolved by the get_current_user dependency (app/dependencies.py).\n- API keys\n  - Secure API keys are generated by generate_api_key() in app/auth.py (sk_ prefix + token_urlsafe).\n  - API clients supply keys via the X-API-Key header. Verification is implemented in verify_api_key (app/dependencies.py): checks key value, is_active, expiration, updates last_used_at and resolves the associated Organization.\n\n### Role-Based Access Control (RBAC)\n- Roles (Owner, Admin, Member, Viewer) are enforced by the require_role dependency in app/dependencies.py. It uses a role_hierarchy mapping and is applied on routes (app/routes.py) to restrict operations such as creating teams, API keys, webhooks, and usage analytics.\n\n### Session & Audit Touchpoints\n- get_current_user updates user.last_login and commits through the DB session (app/dependencies.py).\n- API key verification updates APIKey.last_used_at for auditability (app/dependencies.py).\n- Request timing middleware in main.py logs request/response timings and exposes X-Process-Time; these logs feed usage and analytics workflows.\n\n### Webhooks & Signing\n- Webhook creation and secrets are supported; webhooks include an X-Signature header using HMAC-SHA256 with the webhook secret (docs/api-reference.md). Timeouts and retry behavior are configurable in .env.example (WEBHOOK_TIMEOUT_SECONDS, WEBHOOK_MAX_RETRIES).\n\n### Rate Limiting (Configuration)\n- Subscription-tier limits are documented and configurable via environment variables: RATE_LIMIT_FREE, RATE_LIMIT_STARTER, RATE_LIMIT_PROFESSIONAL in .env.example.\n- The API reference (docs/api-reference.md) lists the effective per-tier limits: Free=100 req/min, Starter=500 req/min, Professional=2000 req/min, Enterprise=Unlimited.\n\n### Deployment & Secrets\n- Production secret management guidance and recommended environment configuration are in docs/deployment.md and .env.example (SECRET_KEY, DATABASE_URL, CORS_ORIGINS, DEBUG). The README.md and deployment guide highlight enabling HTTPS, setting a strong SECRET_KEY, and restricting CORS origins.\n\nFiles:\n- app/auth.py\n- app/dependencies.py\n- app/routes.py\n- main.py\n- .env.example\n- docs/api-reference.md\n- docs/deployment.md\n- README.md",
    "source_files": [
      "app/auth.py",
      "app/dependencies.py",
      "app/routes.py",
      "main.py",
      ".env.example",
      "docs/api-reference.md",
      "docs/deployment.md",
      "README.md"
    ]
  },
  {
    "text": "## Logging, Monitoring, and Health Checks\n\nThis project implements application-level logging, basic request monitoring, and container health checks to support operational visibility.\n\n### Logging\n\n- Initialization: logging is configured in main.py via logging.basicConfig(level=logging.INFO) and a module logger is created (logger = logging.getLogger(__name__)). (main.py)\n- Request logs: an HTTP middleware logs every request with method, path, response status and processing time. The middleware also injects an X-Process-Time header (milliseconds) into responses for latency inspection. The middleware block is in main.py and outputs lines like: \"GET /api/v1/items - Status: 200 - Time: 12ms\". (main.py)\n- Error logging: a global exception handler catches unhandled exceptions, logs them with stack traces (logger.error(..., exc_info=True)) and returns a standardized 500 response. This centralizes unexpected error visibility. (main.py)\n- Configuration: runtime logging settings can be adjusted through environment variables in .env.example (LOG_LEVEL, LOG_FILE) and the app uses the SECRET_KEY/DEBUG vars also present there. ( .env.example )\n- Operational note in code: middleware includes a TODO to forward usage/analytics to the database (commented in main.py), indicating where request/usage logging could be persisted for analytics. (main.py)\n\n### Request Timing and Metrics\n\n- X-Process-Time header: every HTTP response is augmented with X-Process-Time (ms), enabling quick latency checks from clients or synthetic monitors. (main.py)\n- Middleware-level logging provides per-request timing that can be scraped or forwarded to a logging/metrics pipeline for aggregation (middleware in main.py). (main.py)\n\n### Health Checks (Application & Containers)\n\n- Application health endpoint: GET /health returns a small JSON payload with status and timestamp: {\"status\": \"healthy\", \"timestamp\": <float>}. This endpoint is used by container-level checks and external probes. (main.py)\n- Dockerfile HEALTHCHECK: the Docker image defines a HEALTHCHECK that runs a small Python request against http://localhost:8000/health at regular intervals to mark container liveness. This is defined in Dockerfile and attempts to verify the app is serving the health endpoint. (Dockerfile)\n- Compose-level healthchecks and ordering: docker-compose.yml configures a postgres service healthcheck using pg_isready and sets the app service to depend on the db service with condition: service_healthy. This ensures the app container waits for a healthy DB before starting dependent operations. (docker-compose.yml)\n\n### Runtime / Container Logging\n\n- Uvicorn: the container command starts uvicorn with log_level=\"info\" (Dockerfile CMD), so Uvicorn access/error logs will be emitted to stdout/stderr and captured by container log drivers. (Dockerfile)\n- Compose ports and volumes: docker-compose.yml exposes application and database ports and mounts uploads; container logging should therefore be collected via the platform's logging driver or sidecar. (docker-compose.yml)\n\nSource files:\n- main.py\n- docker-compose.yml\n- Dockerfile\n- .env.example",
    "source_files": [
      "main.py",
      "docker-compose.yml",
      "Dockerfile",
      ".env.example"
    ]
  },
  {
    "text": "## Testing, CI/CD, and Release Process\n\nThis project includes the pieces needed for a standard test\u2192build\u2192release pipeline using Poetry/pip for dependency management, Docker for packaging, and Docker Compose / cloud services for deployment. The following summarizes the concrete commands and artifacts present in the repository and a recommended linear flow that maps to CI/CD stages.\n\n### Key artifacts\n- Dependency & metadata: pyproject.toml (package name, version) and requirements.txt (pins used for pip workflows). (.python-version pins toolchain)\n- Test invocation (documented): pytest tests/ (coverage via pytest --cov)\n- Container build: Dockerfile (builds python:3.11-slim image, installs dependencies via Poetry or fallback to requirements.txt, exposes 8000, includes HEALTHCHECK)\n- Local orchestration: docker-compose.yml (Postgres, app, nginx with healthcheck dependencies)\n- Deployment guidance: docs/deployment.md (Docker, Docker Compose, AWS EB/ECS ECR steps, DigitalOcean app spec)\n- Runtime health endpoint & global handlers: main.py (GET /health, logging middleware, DB bootstrap via SQLAlchemy Base.metadata.create_all)\n\n### Test stage (CI job)\n- Install environment: use Poetry (pyproject.toml) or pip install -r requirements.txt depending on chosen runner image.\n- Run unit/integration tests: pytest tests/ (include --cov to collect coverage). Exit non-zero on failures.\n- Optional static checks: linters/formatters are not included but can be added by invoking black/ruff/mypy in the same stage.\n\nExample commands\n- poetry install --no-dev && pytest tests/ --cov\n- pip install -r requirements.txt && pytest tests/ --cov\n\n### Build stage (CI job)\n- Build Docker image using Dockerfile: docker build -t enterprise-todo:${GIT_TAG:-latest} .\n- Run container locally or in CI to smoke-test health: docker run -p 8000:8000 ...; or rely on the Dockerfile HEALTHCHECK which probes /health (Dockerfile uses a python requests call).\n\n### Release & deploy stage (CI job)\n- Tagging: use repository tag (semantic version from pyproject.toml can be synced to Git tag) and use that tag for image: e.g., enterprise-todo:2.0.0\n- Push image to registry (ECR, Docker Hub, or private registry) as described in docs/deployment.md (ECR push steps are outlined there).\n- Run DB migrations before/after deploy: Alembic commands are listed in docs/deployment.md (alembic revision --autogenerate; alembic upgrade head).\n- Deploy: options shown in docs/deployment.md include docker-compose up -d, AWS Elastic Beanstalk (eb deploy), ECS (push to ECR and register task/service), or DigitalOcean App Platform (app.yaml).\n\n### Runtime checks and observability\n- Health checks: main.py exposes GET /health; Dockerfile includes a HEALTHCHECK that queries this endpoint.\n- Logging: main.py configures request logging and a global exception handler; these integrate into CI/CD smoke tests and orchestrator health checks.\n\nSource files: the CI/CD flow maps to these repository files for commands, image build, health checks, and deployment notes.",
    "source_files": [
      "docs/deployment.md",
      "README.md",
      "pyproject.toml",
      "Dockerfile",
      "docker-compose.yml",
      "requirements.txt",
      "main.py",
      ".python-version"
    ]
  },
  {
    "text": "## Troubleshooting & Maintenance\n\nThis guide consolidates diagnostic checks, maintenance tasks, and recovery commands for the Enterprise Todo Platform.\n\n### Quick health checks\n- API health: GET /health (returns status + timestamp). (main.py)\n- Container health: Dockerfile defines a HEALTHCHECK calling /health; docker-compose defines a pg_isready healthcheck for Postgres. (Dockerfile, docker-compose.yml)\n\n### Logs & error collection\n- Application logs: stdout from Uvicorn (container logs). main.py configures logging and a global exception handler that returns 500 for unhandled errors \u2014 inspect container logs for stack traces. (main.py)\n- Persisted logs: check host-mounted volumes or configured LOG_FILE (see .env.example) if file logging is enabled. (.env.example)\n- External monitoring: docs recommend Sentry integration and log aggregation services for error/tracing. (docs/deployment.md)\n\n### Common failure modes & diagnostics\n- App won't start: inspect `docker logs todo_app` or `journalctl` if running systemd; check Dockerfile CMD (uvicorn main:app). Verify dependencies installed during image build. (Dockerfile)\n- DB connection errors: confirm DATABASE_URL env var, container networking, and Postgres healthcheck (pg_isready). If using the default local SQLite in development, confirm file existence and permissions. (docker-compose.yml, app/database.py, .env.example)\n- Migrations missing / schema mismatch: run Alembic migrations (alembic upgrade head) as documented in deployment guide. (docs/deployment.md)\n- Long response times: review request timing logged by middleware (X-Process-Time header added by main.py) and examine DB query performance. (main.py)\n\n### Recovery & common commands\n- Recreate services: docker-compose down && docker-compose up -d --build (docker-compose.yml, Dockerfile)\n- Tail logs: docker-compose logs -f app\n- Run migrations: alembic upgrade head (docs/deployment.md)\n- Manual DB check: docker exec -it todo_db pg_isready -U <user> or pg_dump for backups (docker-compose.yml, docs/deployment.md)\n\n### Backups & restores\n- Postgres backups: use pg_dump as shown in the deployment guide and schedule cron jobs for automated dumps. (docs/deployment.md)\n- File uploads: ensure uploads volume is backed up (docker-compose mounts ./uploads). (.env.example, docker-compose.yml)\n\n### Maintenance cadence\n- Weekly: review error logs, disk usage, and DB connections.\n- Monthly: apply OS and Python dependency security updates; run migrations in staging before production.\n- Quarterly: performance tuning and backup restore drills. (docs/deployment.md)\n\nFiles referenced: main.py, app/database.py, docker-compose.yml, Dockerfile, .env.example, docs/deployment.md, docs/getting-started.md",
    "source_files": [
      "main.py",
      "app/database.py",
      "docker-compose.yml",
      "Dockerfile",
      ".env.example",
      "docs/deployment.md",
      "docs/getting-started.md"
    ]
  },
  {
    "text": "# Feature Comparison & Monetization\n\n## Transformation Overview\n\nThis project converts a minimal todo app into a production-grade multi-tenant SaaS platform with enterprise features, security, observability, and a concrete monetization model. Key documentation that defines this transformation includes docs/feature-comparison.md and README.md (see below).\n\n## Core Feature Delta (Before \u2192 After)\n\n- Authentication: none \u2192 JWT + API keys, password hashing (bcrypt) (docs/feature-comparison.md, README.md)\n- Multi-tenancy: single-user list \u2192 Organizations, Teams, RBAC (Owner/Admin/Member/Viewer) (docs/index.md)\n- Items: title/description \u2192 statuses, priorities, due dates, subtasks, time tracking, assignees, tags (docs/feature-comparison.md)\n- Collaboration: none \u2192 comments, activity logs, attachments, team assignments (docs/index.md)\n- Integrations: none \u2192 API keys, webhooks, HMAC signature verification (docs/api-reference.md)\n- Observability & ops: none \u2192 health checks, request logging, Docker + Compose, Nginx reverse proxy (docs/feature-comparison.md, README.md)\n\n## Database & API Evolution\n\n- Schema expands from a single in-memory Item to ~12 relational models: organizations, users, teams, items (with relations), tags, comments, attachments, API keys, webhooks, usage logs, activity logs (docs/feature-comparison.md, docs/SUMMARY.md).\n- API grows from ~5 CRUD endpoints to 30+ REST endpoints covering auth, orgs, teams, items, comments, tags, API keys, webhooks, activity, and analytics (docs/api-reference.md).\n\n## Monetization: Tiers & Revenue Enablers\n\n- Subscription tiers defined: Free, Starter, Professional, Enterprise. Each tier has limits on users/items and exposes features progressively (tags, teams, webhooks, analytics, SLA) (README.md, docs/index.md).\n- Revenue enablers: per-organization usage tracking, API keys for paid integrations, webhooks as paid add-ons, analytics as upsell, seat-based pricing, and enterprise SLAs (docs/feature-comparison.md, docs/index.md).\n\n## Path to $10M ARR (summary)\n\n- Target model: achieve ~10,000 paying customers at an average revenue per account \u2248 $83/month (README.md, docs/feature-comparison.md).\n- Growth levers called out: freemium conversion, seat expansion, tier upgrades, add-on purchases (advanced analytics, custom integrations, priority support) (docs/SUMMARY.md).\n\n## Relevant source files\n\nSee: docs/feature-comparison.md, README.md, docs/index.md, docs/SUMMARY.md, docs/api-reference.md\n",
    "source_files": [
      "docs/feature-comparison.md",
      "README.md",
      "docs/index.md",
      "docs/SUMMARY.md",
      "docs/api-reference.md"
    ]
  }
]